{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buiding Whoosh Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "\n",
    "schema = Schema(filename=ID(stored=True),\n",
    "                line_num=ID(stored=True),\n",
    "                content=TEXT(analyzer=StemmingAnalyzer())\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "from whoosh import index\n",
    "\n",
    "# Note, this clears the existing index in the directory\n",
    "ix = index.create_in(\"hp\", schema)\n",
    "\n",
    "# Get a writer form the created index in \n",
    "writer = ix.writer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder:  hp\n",
      "root =  hp\n",
      "Processing File: hp/CHAPTER 1.txt\n",
      "Indexed:  hp/CHAPTER 1.txt\n",
      "Processing File: hp/CHAPTER 2.txt\n",
      "Indexed:  hp/CHAPTER 2.txt\n",
      "Processing File: hp/CHAPTER 3.txt\n",
      "Indexed:  hp/CHAPTER 3.txt\n",
      "Processing File: hp/CHAPTER 4.txt\n",
      "Indexed:  hp/CHAPTER 4.txt\n",
      "Processing File: hp/CHAPTER 5.txt\n",
      "Indexed:  hp/CHAPTER 5.txt\n",
      "Processing File: hp/CHAPTER 6.txt\n",
      "Indexed:  hp/CHAPTER 6.txt\n",
      "Processing File: hp/CHAPTER 7.txt\n",
      "Indexed:  hp/CHAPTER 7.txt\n",
      "Processing File: hp/CHAPTER 8.txt\n",
      "Indexed:  hp/CHAPTER 8.txt\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "recursing into  MAIN.tmp\n",
      "Processing folder:  MAIN.tmp\n",
      "root =  hp/MAIN.tmp\n",
      "Unhandled File\n"
     ]
    }
   ],
   "source": [
    "def loadFile(writer, fname):\n",
    "    '''\n",
    "    Read file contents, load into database.\n",
    "    '''\n",
    "    line_no = 1\n",
    "    with open(fname, 'r') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip('\\n')\n",
    "            line_no += 1\n",
    "            writer.add_document(filename=fname, line_num=str(line_no),content=line)\n",
    "    print(\"Indexed: \", fname)\n",
    "\n",
    "\n",
    "def processFolder(writer,folder):\n",
    "    '''\n",
    "    Process a folder for files and subfolders\n",
    "    '''\n",
    "    print('Processing folder: ',folder)\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        print(\"root = \", root)\n",
    "        # Process Files\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                filename = os.path.join(root, file)\n",
    "                print('Processing File:',filename)\n",
    "                loadFile(writer,filename)\n",
    "            else:\n",
    "                print(\"Unhandled File\")\n",
    "        # Recurse into subfolders\n",
    "        for d in dirs:\n",
    "            print(\"recursing into \",d)\n",
    "            processFolder(writer,d)\n",
    "\n",
    "# Functions defined,  get the party started:\n",
    "processFolder(writer,\"hp\")\n",
    "writer.commit() # save changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '708'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 2.txt', 'line_num': '396'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 1.txt', 'line_num': '97'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 2.txt', 'line_num': '45'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 3.txt', 'line_num': '18'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 3.txt', 'line_num': '339'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 5.txt', 'line_num': '916'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '349'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '424'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '756'}>\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "qp = QueryParser(\"content\", schema=ix.schema)\n",
    "q = qp.parse(u\"Harry\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    results = s.search(q)\n",
    "    for hit in results:\n",
    "        print(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit {'filename': 'hp/CHAPTER 2.txt', 'line_num': '91'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 2.txt', 'line_num': '258'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 2.txt', 'line_num': '396'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 5.txt', 'line_num': '296'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 5.txt', 'line_num': '750'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 5.txt', 'line_num': '809'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 5.txt', 'line_num': '933'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '402'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '708'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '809'}>\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import scoring\n",
    "\n",
    "qp = QueryParser(\"content\", schema=ix.schema)\n",
    "q = qp.parse(u\"Harry\")\n",
    "\n",
    "with ix.searcher(weighting=scoring.TF_IDF()) as s:\n",
    "    results = s.search(q)\n",
    "    for hit in results:\n",
    "        print(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '402'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '708'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '809'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '6'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '7'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '8'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '11'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '14'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '20'}>\n",
      "<Hit {'filename': 'hp/CHAPTER 6.txt', 'line_num': '41'}>\n"
     ]
    }
   ],
   "source": [
    "from whoosh.query import *\n",
    "\n",
    "with ix.searcher(weighting=scoring.TF_IDF()) as s:\n",
    "    qp = QueryParser(\"content\", ix.schema)\n",
    "    user_q = qp.parse(u\"Harry\")\n",
    "\n",
    "    # Only show documents in the \"rendering\" chapter\n",
    "    allow_q = Term(\"filename\", \"hp/CHAPTER 6.txt\")\n",
    "    \n",
    "    results = s.search(user_q, filter=allow_q)\n",
    "    for hit in results:\n",
    "        print(hit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
